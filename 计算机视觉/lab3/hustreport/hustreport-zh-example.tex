%%
%% This is file `hustreport-zh-example.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% hustreport.dtx  (with options: `example-zh')
%% 
%% This is a generated file.
%% 
%% Copyright (C) 2013-2014 by Xu Cheng <xucheng@me.com>
%%               2014-2016 by hust-latex <https://github.com/hust-latex>
%% 
%% This work may be distributed and/or modified under the
%% conditions of the LaTeX Project Public License, either version 1.3
%% of this license or (at your option) any later version.
%% The latest version of this license is in
%%   http://www.latex-project.org/lppl.txt
%% and version 1.3 or later is part of all distributions of LaTeX
%% version 2005/12/01 or later.
%% 
%% This work has the LPPL maintenance status `maintained'.
%% 
%% The Current Maintainer of this work is hust-latex Organization.
%% 
%% This work consists of the files hustreport.dtx,
%% hustreport.ins and the derived file hustreport.cls
%% along with its document and example files.
%% 
%% \CharacterTable
%% {Upper-case    \A\B\C\D\E\F\G\H\I\J\K\L\M\N\O\P\Q\R\S\T\U\V\W\X\Y\Z
%%  Lower-case    \a\b\c\d\e\f\g\h\i\j\k\l\m\n\o\p\q\r\s\t\u\v\w\x\y\z
%%  Digits        \0\1\2\3\4\5\6\7\8\9
%%  Exclamation   \!     Double quote  \"     Hash (number) \#
%%  Dollar        \$     Percent       \%     Ampersand     \&
%%  Acute accent  \'     Left paren    \(     Right paren   \)
%%  Asterisk      \*     Plus          \+     Comma         \,
%%  Minus         \-     Point         \.     Solidus       \/
%%  Colon         \:     Semicolon     \;     Less than     \<
%%  Equals        \=     Greater than  \>     Question mark \?
%%  Commercial at \@     Left bracket  \[     Backslash     \\
%%  Right bracket \]     Circumflex    \^     Underscore    \_
%%  Grave accent  \`     Left brace    \{     Vertical bar  \|
%%  Right brace   \}     Tilde         \~}
\documentclass[format=draft,language=chinese,category=academic-report]{hustreport}

\stuno{1111}
\title{基于前馈神经网络的分类任务设计}
\author{thezmmm}
\major{数据科学与大数据技术}
\class{000}
\advisor{杨卫}

\begin{document}

\frontmatter
\maketitle
\tableofcontents
\mainmatter

\chapter{实验要求}
本实验旨在设计一个卷积神经网络（Convolutional Neural Network, CNN），用于比较两张MNIST手写数字图片是否为同一个数字。具体要求如下：
\begin{enumerate}
\item 数据集准备
从MNIST数据集的训练集中选取10\%作为本实验的训练图片，从MNIST数据集的测试集中选取10\%作为本实验的测试图片。为了确保数据集的多样性，需要对这些选取的图片进行适当的处理。处理方法可以包括：
\begin{itemize}
\item 图像归一化：将图像进行归一化处理，将像素值缩放到0-1的范围。
\item 图像增强：应用一些图像增强技术，如旋转、平移、缩放、翻转等，以增加数据集的多样性和鲁棒性。
\end{itemize}
在实验报告中，需要详细说明数据集的构成，包括训练集和测试集的数量以及经过处理后的图像特征。

\item 神经网络架构

设计一个适合本实验的卷积神经网络架构。建议的网络架构可以包括卷积层、池化层、全连接层等。详细描述网络的层数、每一层的参数设置（如卷积核大小、步长、激活函数等）以及网络中的参数数量。

\item 模型训练和评估

使用选定的深度学习框架，将准备好的训练集输入到神经网络中进行模型训练。每一轮使用mini-batch进行训练，并记录每一轮训练后的模型在训练集和测试集上的损失。在训练过程中，可以选择合适的优化算法（如随机梯度下降法）和损失函数（如交叉熵损失函数）。

在实验报告中，需要提供训练过程中每一轮mini-batch训练后的损失值，并可视化损失曲线。同时，记录最终训练集和测试集上的准确率。

\item 实验分析
在实验报告中，对实验结果进行分析和讨论。可以讨论以下问题：
\begin{itemize}
\item 实验结果的准确率如何？是否满足要求？
\item 选用的卷积神经网络架构对实验结果有何影响？
\item 数据集的处理方法是否对实验结果有提升？
\item 训练过程中的损失曲线有何特点？
\end{itemize}
在实验分析部分，可以结合实验结果进行讨论，提出改进的方向以及可能的问题或限制。
\end{enumerate}
\chapter{实验内容}
\section{数据集处理}
在实验中，对选择的MNIST数据集进行了一系列处理以形成用于本次实验的训练集和测试集。下面是对数据集的详细处理流程：
\begin{enumerate}
\item 加载MNIST数据集：
使用tf.keras.datasets.mnist.load\_data()函数加载MNIST数据集，将训练集和测试集分别赋值给train\_images, train\_labels和test\_images, test\_labels。

\item 像素值缩放：
将图像的像素值进行缩放处理，将像素值范围从0到255缩放到0到1之间。这一步骤是为了将输入的图像数据归一化，以便更好地进行模型训练。

\begin{lstlisting}
train_images = train_images / 255.0
test_images = test_images / 255.0
\end{lstlisting}

\item 分割训练集和测试集：
使用train\_test\_split函数将训练集和测试集分割为10\%的数据，并保持标签的分布一致。这样做是为了在实验中使用较小的数据集，以减少计算资源和时间成本。

\begin{lstlisting}
train_images, _, train_labels, _ = train_test_split(train_images, train_labels, train_size=0.01, stratify=train_labels)
test_images, _, test_labels, _ = train_test_split(test_images, test_labels, train_size=0.01, stratify=test_labels)
\end{lstlisting}

\item 构建用于本次实验的训练集和测试集：
根据实验要求，我们需要构建用于比较两张MNIST手写数字图片是否为同一个数字的数据集。为此，定义了一个名为create\_dataset的函数来实现。
\begin{itemize}
\item 对于每一对不同的图片组合，将两张图片水平拼接在一起，形成一张新的图片combined\_image。
\item 判断这两张图片是否为同一个数字，如果是，则标签is\_same\_digit为1，否则为0。
\item 将combined\_image添加到combined\_images列表中，将is\_same\_digit添加到combined\_labels列表中。
\item 最后，将combined\_images和combined\_labels转换为NumPy数组，并作为最终的训练集和测试集返回。
\end{itemize}
\begin{lstlisting}
# 构建用于本次实验的训练集和测试集
def create_dataset(images, labels):
    num_samples = len(images)
    combined_images = []
    combined_labels = []

    for i in range(num_samples):
        for j in range(i,num_samples):
            if i != j:
                # 将两张图片合并
                combined_image = np.concatenate([images[i], images[j]], axis=1)
                combined_images.append(combined_image)

                # 判断是否为同一个数字
                is_same_digit = int(labels[i] == labels[j])
                combined_labels.append(is_same_digit)

    combined_images = np.array(combined_images)
    combined_labels = np.array(combined_labels)

    return combined_images, combined_labels

# 创建训练集和测试集
train_images, train_labels = create_dataset(train_images, train_labels)
test_images, test_labels = create_dataset(test_images, test_labels)
\end{lstlisting}
\end{enumerate}
通过以上处理，得到了用于本次实验的训练集train\_images和train\_labels，以及测试集test\_images和test\_labels。这些数据集将用于训练卷积神经网络模型，并进行实验的评估和分析。
\section{神经网络模型}
\begin{lstlisting}
# 构建卷积神经网络模型
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 56, 1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dropout(0.5))  # 添加 Dropout 层
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))
\end{lstlisting}
上述代码构建了一个卷积神经网络（Convolutional Neural Network, CNN）模型，用于比较两张MNIST手写数字图片是否为同一个数字。下面是对神经网络模型的详细描述：
\begin{enumerate}
\item 输入层：模型接受输入的图像形状为(28, 56, 1)，表示图像的高度为28像素，宽度为56像素，通道数为1（灰度图像）。
\item 卷积层1：包含32个卷积核，每个卷积核的大小为(3, 3)，使用ReLU激活函数。
\item 最大池化层1：使用(2, 2)的池化窗口进行最大池化操作，对特征图进行下采样。
\item 卷积层2：包含64个卷积核，每个卷积核的大小为(3, 3)，使用ReLU激活函数。
\item 最大池化层2：使用(2, 2)的池化窗口进行最大池化操作，对特征图进行下采样。
\item 扁平化层：将特征图展平为一维向量，以便连接到全连接层。
\item Dropout层：添加一个Dropout层，以减少过拟合的可能性。设置Dropout率为0.5，表示在训练过程中每次更新时，随机选择50%的神经元进行丢弃。
\item 全连接层1：包含64个神经元，使用ReLU激活函数。
\item 全连接层2：包含1个神经元，使用Sigmoid激活函数，输出范围为[0, 1]，用于预测两张图片是否为同一个数字。
\end{enumerate}
\begin{figure}[htbp]
\centering
\includegraphics[scale=0.3]{img/png.png}
\caption{神经网络架构图}
\end{figure}

\section{网络参数}
下面是对其他参数的详细介绍：
\begin{enumerate}
\item 优化器（Optimizer）：

这里选择了Adam优化器作为模型的优化器。Adam（Adaptive Moment Estimation）是一种自适应学习率的优化算法，结合了动量方法和RMSProp方法。它能够自动调整学习率，并根据每个参数的梯度动态调整学习率的大小，从而加快模型的训练速度并提高收敛性。

\item 学习率（Learning Rate）：

Adam算法会自动调整学习率，因此并没有显式指定学习率的值。默认情况下，Adam优化器使用一个较小的学习率，对大多数问题都能够提供良好的性能。如果需要进一步调整学习率，可以通过调整其他相关参数来实现。

\item 损失函数（Loss Function）：

选择了二元交叉熵损失函数（binary\_crossentropy）作为模型的损失函数。二元交叉熵损失函数通常用于处理二分类问题，用于度量模型输出与真实标签之间的差异。它可以衡量模型对于两个类别的分类准确性，并通过最小化损失函数来优化模型的参数。

\item 训练轮数（Epochs）：

将训练的轮数设置为10，表示将整个训练集的样本在模型上训练10次。每一轮的训练过程将所有样本都用于参数更新。通过增加训练轮数，模型有更多的机会学习数据集中的模式和特征，但过多的训练轮数可能导致过拟合。

\item 批量大小（Batch Size）：

将批量大小设置为32，表示每次从训练集中随机选择32个样本进行一次参数更新。批量大小决定了在一次参数更新中使用的样本数量。较大的批量大小可以加快训练速度，但也会增加内存需求。较小的批量大小可以提供更稳定的梯度估计，但可能会导致训练过程的噪声增加。
\end{enumerate}
通过设置合适的优化器、损失函数、训练轮数和批量大小等参数，可以对神经网络模型进行有效的训练和优化，以提高模型的性能和泛化能力。需要根据具体的问题和数据集特点进行参数的调整和优化。
\chapter{实验结果}
\section{结果分析}
根据实验结果，我们可以对模型的性能进行详细分析。实验结果包括每个训练轮数的准确率（accuracy）和损失（loss）的数值，下面是对每个指标的分析：
\begin{figure}[htbp]
\centering
\includegraphics[scale=0.4]{img/epoch_accuracy.png}
\caption{epoch\_accuracy}
\end{figure}
\begin{figure}[htbp]
\centering
\includegraphics[scale=0.4]{img/epoch_loss.png}
\caption{epoch\_loss}
\end{figure}
\begin{enumerate}
\item 准确率（Accuracy）：
\begin{itemize}
\item Epoch 0: 准确率为0.949。
\item Epoch 1: 准确率显著提高至0.993。
\item Epoch 2: 准确率进一步提高至0.997。
\item Epoch 3: 准确率达到0.997，接近于完美分类。
\item Epoch 4-9: 准确率持续提高，最终在Epoch 9达到0.999。
\end{itemize}
从实验结果可以看出，随着训练轮数的增加，模型的准确率逐渐提高，这说明模型在训练集上学习到了更多的特征和模式，并能够更好地对图像进行分类。
\item 损失（Loss）：
\begin{itemize}
\item Epoch 0: 损失为0.143。
\item Epoch 1: 损失显著下降至0.022。
\item Epoch 2: 损失进一步下降至0.010。
\item Epoch 3: 损失继续下降至0.008。
\item Epoch 4-9: 损失持续减小，最终在Epoch 9降至0.003。
\end{itemize}
\end{enumerate}
从实验结果可以看出，随着训练轮数的增加，模型的损失逐渐减小，这表明模型学习到了更好的表示和特征提取能力，并且能够更好地拟合训练数据。

综合来看，模型在训练过程中表现出了很好的性能。准确率和损失都随着训练轮数的增加而改善，说明模型能够有效地学习到数据的模式和特征。最终，模型在训练集上达到了很高的准确率（约99.9\%），并且损失趋近于0，这表明模型能够很好地对两张MNIST手写数字图片进行分类，并且拟合了训练数据的分布。

根据在测试集上的实验结果，我们可以对模型在测试集上的性能进行分析。下面是对测试集的损失和准确率的详细分析：
\begin{enumerate}
\item 测试集损失（Test Loss）：测试集损失为0.144。

测试集损失反映了模型在测试集上的拟合程度。较低的损失值表示模型能够很好地拟合测试数据，而较高的损失值则表示模型与测试数据之间存在较大的差异。

在这个实验中，模型在测试集上的损失值为0.144，这表明模型能够在一定程度上适应测试数据，并且具有较好的拟合能力。

\item 测试集准确率（Test Accuracy）：测试集准确率为0.971。

测试集准确率是衡量模型在测试集上分类准确性的指标。它表示模型正确分类的样本比例。

在这个实验中，模型在测试集上的准确率为0.971，这意味着模型能够准确地对两张MNIST手写数字图片进行分类的能力较高。
\end{enumerate}
综合来看，模型在测试集上表现出了很好的性能。测试集损失较低，准确率较高，这表明模型在测试集上能够很好地泛化并具有较好的分类能力。
\section{数据处理}
数据集的处理方法对实验结果具有重要影响。在这个实验中，我们对MNIST数据集进行了一些处理，以创建适用于实验的训练集和测试集。

这些数据集处理方法的选择可以对实验结果产生积极影响：
\begin{enumerate}
\item 数据缩放可以确保数据处于相似的尺度范围内，帮助模型更好地进行优化，并提高模型的稳定性和收敛性。

\item 数据拆分可以减少训练和测试过程的计算负担，加速实验的进行。这对于快速迭代和调试模型架构和超参数非常有帮助。

\item 数据增强可以增加训练集的多样性和数量，提供更多的样本供模型学习。这可以帮助模型更好地泛化，减少过拟合的风险。
\end{enumerate}
\section{神经网络架构}
我们使用了一个简单的卷积神经网络（CNN）架构来进行实验。该架构具有两个卷积层和池化层，以及两个全连接层和一个输出层。

CNN架构对实验结果的影响可能有以下方面：
\begin{enumerate}
\item 特征提取能力：卷积层和池化层是CNN的核心组件，用于提取图像中的特征。较深的卷积层可以捕捉更高级别的抽象特征，从而提高模型的分类性能。在实验中，我们使用了两个卷积层和池化层，允许模型学习更复杂的图像特征，相比于较浅的网络结构，这可能会带来更好的实验结果。

\item 模型复杂度：CNN架构的深度和宽度会影响模型的复杂度。更深或更宽的网络通常具有更多的参数，可以提供更强大的建模能力，但也容易导致过拟合。在实验中，我们使用了两个卷积层和池化层，以及两个全连接层。这种相对较简单的架构可能在一定程度上限制了模型的表示能力，但也有助于减少过拟合的风险。

\item Dropout层：在实验中，我们在全连接层之间添加了一个Dropout层，以减少过拟合。Dropout层可以随机地丢弃一部分神经元的输出，从而强制模型学习更鲁棒和泛化的特征。通过减少神经元之间的依赖关系，Dropout层有助于提高模型的泛化能力，并可以对实验结果产生积极影响。
\end{enumerate}
综上所述，选择卷积神经网络架构对实验结果具有重要影响。通过增加网络深度、宽度和使用适当的正则化技术，可以提高模型的特征提取能力、泛化能力和鲁棒性，从而改善实验结果。
\chapter{总结}
在这个实验中，我们训练了一个神经网络模型来对MNIST手写数字图像进行分类。模型使用了Adam优化器和二元交叉熵损失函数，并在训练过程中进行了10个训练轮数，每个批次包含32个样本。

通过训练和测试集上的结果分析，我们可以得出以下结论：

训练集性能：模型在训练集上表现出了非常高的准确率（约99.9\%）和较低的损失值（约0.003）。这表明模型能够很好地拟合训练数据的特征和模式，并具有较强的分类能力。

测试集性能：模型在测试集上表现出了较高的准确率（约97.1\%）和较低的损失值（约0.144）。这表明模型具有良好的泛化能力，能够对未见过的数据进行准确分类。

综合来看，通过实验，我们建立了一个能够准确分类MNIST手写数字图像的神经网络模型。模型在训练集和测试集上都表现出了很好的性能，说明模型能够学习到数据的特征，并能够泛化到新的样本上。然而，对于进一步评估模型的性能，可以考虑使用更多的评估指标和测试数据，以确保模型的鲁棒性和可靠性。此外，还可以尝试调整模型的架构、超参数和数据增强等方法，以提高模型的性能和泛化能力。
\end{document}
\endinput
%%
%% End of file `hustreport-zh-example.tex'.
